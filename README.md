# 635_Project Proposal 
## Group detail
__Course Name:__ E&C-ENG 535:635 (157437) FA24  
__Instructor:__ Fatima Anwar  
__Group Member:__ HAN GAO, CAIYUE CHEN  
__Project:__ Federated Learning on Multimodal Sensor Data  
__DATE:__ 28/09/2024  

## Motivation
Our group has chosen Federated Learning on Multimodal Sensor Data as our Porject In recent years, we’ve seen that data security and privacy in machine learning are crucial issues. Based on our current research, Federated Learning has unique advantages in various fields. It allows devices to train data without sharing it, which is essential in privacy-sensitive fields like healthcare. Additionally, I believe this technology is flexible, as it can utilize data from multiple sources, meaning that distributed sensors and devices can be used as needed.  
Finally, our recent studies have highlighted the importance of time synchronization and communication. Federated Learning allows data to be trained and updated directly on devices, reducing the need for constant communication with servers, which lowers communication delays and reduces the need for time synchronization. This can be applied to devices like autonomous vehicles and wearable health monitors. For these reasons, our group believes that Federated Learning is a technology we want to study and is definitely worth learning.

## Project Details
__Goal:__ Understand and benchmark different multimodal datasets in a federated setting

__Deliverables:__  
• Understand multimodal federated learning  
• Use given datasets to reproduce the results in the paper  
• Perform a per-class accuracy analysis of the results and observe the effect of skewed data distribution on the per-class accuracy  
• Evaluate the system on a multimodal dataset that is relatively balanced in class distribution  
